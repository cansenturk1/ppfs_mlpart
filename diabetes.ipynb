{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "843d0307",
   "metadata": {},
   "source": [
    "imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8c42f540",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, precision_score, recall_score\n",
    "from sklearn.model_selection import StratifiedKFold, cross_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d1cbabdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def preprocess(file_path,split_value,target_column_index,has_header):\n",
    "    \"\"\"this function is used for taking the dataset from .csv file making a test train split\n",
    "    and x, y split (has header is either True or False)\"\"\"\n",
    "\n",
    "    #reading the .csv\n",
    "    if has_header:\n",
    "        df = pd.read_csv(file_path, header=0, delimiter=\",\")  # First row as header\n",
    "        print(f\"Dataset shape: {df.shape}\")\n",
    "        print(f\"Column names: {list(df.columns)}\")\n",
    "    else:\n",
    "        df = pd.read_csv(file_path, header=None, delimiter=\",\")  # No header row\n",
    "        print(f\"Dataset shape: {df.shape}\")\n",
    "\n",
    "    #making target variable split\n",
    "    x_ds = df.drop(df.columns[target_column_index], axis=1)  # All except target\n",
    "    y_ds = df.iloc[:, target_column_index]  # Target column only\n",
    "\n",
    "    #making test train split\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x_ds, y_ds, test_size=split_value, random_state=10, shuffle= True)\n",
    "    print(f'shape of x training: {x_train.shape}')\n",
    "    print(f'shape of x testing: {x_test.shape}')\n",
    "\n",
    "    return x_train, x_test, y_train, y_test, x_ds, y_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb769c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def implement(model):\n",
    "    \"\"\"this function contains implementation (modeling and fitting) on the dataset with 1 \n",
    "    initiation and shows the results of the implementations.\n",
    "    Note: This function doesn't have compile so it is not appoprate to use this function for perceptron learning algs.\n",
    "    because it doesn't have training vs test accuracy comparison and doesn't have epochs and .argmax(axis=1) \"\"\"\n",
    "    #initiante ml\n",
    "    model.fit(x_train, y_train)\n",
    "    #model evaluation\n",
    "    y_pred = model.predict(x_test)\n",
    "\n",
    "    print(f'Classification report: {classification_report(y_test, y_pred)}')\n",
    "    print(f\"Accuracy score is: {accuracy_score(y_test,y_pred)}\")\n",
    "    print(f\"Percision score is: {precision_score(y_test,y_pred, average='weighted')}\")\n",
    "    print(f\"Recall score is: {recall_score(y_test,y_pred, average='weighted')}\")\n",
    "    print(f'Confusion matrix: \\n{confusion_matrix(y_test, y_pred)}')\n",
    "\n",
    "    # StratifiedKFold evaluations\n",
    "    skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=10)\n",
    "    scoring = ['accuracy', 'precision_weighted', 'recall_weighted']\n",
    "    cv_results = cross_validate(model, x_ds, y_ds, cv=skf, scoring=scoring)\n",
    "    print(f\"StratifiedKFold CV Accuracy: {cv_results['test_accuracy'].mean():.4f} (+/- {cv_results['test_accuracy'].std() * 2:.4f})\")\n",
    "    print(f\"StratifiedKFold CV Precision: {cv_results['test_precision_weighted'].mean():.4f} (+/- {cv_results['test_precision_weighted'].std() * 2:.4f})\")\n",
    "    print(f\"StratifiedKFold CV Recall: {cv_results['test_recall_weighted'].mean():.4f} (+/- {cv_results['test_recall_weighted'].std() * 2:.4f})\")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e68b2693",
   "metadata": {},
   "source": [
    "Select the dataset!\n",
    "\n",
    "Runs the preprocess for diffrent datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "65c5cd02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (13611, 17)\n",
      "Column names: ['Area', 'Perimeter', 'MajorAxisLength', 'MinorAxisLength', 'AspectRation', 'Eccentricity', 'ConvexArea', 'EquivDiameter', 'Extent', 'Solidity', 'roundness', 'Compactness', 'ShapeFactor1', 'ShapeFactor2', 'ShapeFactor3', 'ShapeFactor4', 'Class']\n",
      "shape of x training: (10888, 16)\n",
      "shape of x testing: (2723, 16)\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test, x_ds, y_ds = preprocess(\"beans_kmeans.csv\", 0.2, 16, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5888940",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test, x_ds, y_ds = preprocess(\"diabetes_kmeans.csv\", 0.2, 8, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92cab410",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test, x_ds, y_ds = preprocess(\"divorce.csv\", 0.2, 54, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f054b17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test, x_ds, y_ds = preprocess(\"parkinsons_kmeans.csv\", 0.2, 17, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1930ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test, x_ds, y_ds = preprocess(\"rice_binned_kmeans.csv\", 0.2, 7, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d39b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test, x_ds, y_ds = preprocess(\"wdbc_binned_kmeans.csv\", 0.2, 1, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a658522",
   "metadata": {},
   "source": [
    "Run the implement function for diffrent models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c4bcee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#KNN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "implement(KNeighborsClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd68222",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ada Boost\n",
    "from sklearn.ensemble import AdaBoostClassifier \n",
    "implement(AdaBoostClassifier(n_estimators=100, random_state = 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba3aeb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVM\n",
    "from sklearn.svm import SVC \n",
    "implement(SVC(max_iter = -1, random_state=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1c80a70a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report:               precision    recall  f1-score   support\n",
      "\n",
      "    BARBUNYA       0.82      0.77      0.79       233\n",
      "      BOMBAY       1.00      0.99      1.00       118\n",
      "        CALI       0.85      0.90      0.87       330\n",
      "    DERMASON       0.94      0.86      0.90       706\n",
      "       HOROZ       0.96      0.92      0.94       396\n",
      "       SEKER       0.91      0.94      0.93       411\n",
      "        SIRA       0.79      0.89      0.84       529\n",
      "\n",
      "    accuracy                           0.89      2723\n",
      "   macro avg       0.90      0.90      0.90      2723\n",
      "weighted avg       0.89      0.89      0.89      2723\n",
      "\n",
      "Accuracy score is: 0.8887256702166728\n",
      "Percision score is: 0.8924397974910343\n",
      "Recall score is: 0.8887256702166728\n",
      "Confusion matrix: \n",
      "[[179   0  42   0   0   1  11]\n",
      " [  1 117   0   0   0   0   0]\n",
      " [ 27   0 297   0   4   1   1]\n",
      " [  0   0   0 604   0  20  82]\n",
      " [  0   0  11   6 365   0  14]\n",
      " [  5   0   0   5   0 387  14]\n",
      " [  6   0   0  27  11  14 471]]\n",
      "StratifiedKFold CV Accuracy: 0.8899 (+/- 0.0154)\n",
      "StratifiedKFold CV Precision: 0.8932 (+/- 0.0155)\n",
      "StratifiedKFold CV Recall: 0.8899 (+/- 0.0154)\n"
     ]
    }
   ],
   "source": [
    "#Gaussian Naive Bayes\n",
    "from sklearn.naive_bayes import GaussianNB \n",
    "implement(GaussianNB())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c072b9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forests\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "implement(RandomForestClassifier())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816975ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decesion Trees\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "implement(DecisionTreeClassifier())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.10)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
