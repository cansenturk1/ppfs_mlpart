{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25028203",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c7a3255",
   "metadata": {},
   "source": [
    "reading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8de2bd59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv(file_path,has_header):\n",
    "    \"\"\"this function is used for taking the dataset from .csv file making a test train split\n",
    "    and x, y split (has header is either True or False)\"\"\"\n",
    "\n",
    "    #reading the .csv\n",
    "    if has_header:\n",
    "        df = pd.read_csv(file_path, header=0, delimiter=\",\")  # First row as header\n",
    "        print(f\"Dataset shape: {df.shape}\")\n",
    "        print(f\"Column names: {list(df.columns)}\")\n",
    "    else:\n",
    "        df = pd.read_csv(file_path, header=None, delimiter=\",\")  # No header row\n",
    "        print(f\"Dataset shape: {df.shape}\")\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c218bad",
   "metadata": {},
   "source": [
    "selecting the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d53110",
   "metadata": {},
   "source": [
    "dataset_name= \"beans\"\n",
    "df = read_csv(dataset_name + \"_kmeans.csv\", True)\n",
    "label_column = 16\n",
    "number_of_sets = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1246d40d",
   "metadata": {},
   "source": [
    "dataset_name= \"diabetes\"\n",
    "df = read_csv(dataset_name + \"_kmeans.csv\", True)\n",
    "label_column = 8\n",
    "number_of_sets = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d3ad47d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (170, 55)\n",
      "Column names: ['Atr1', 'Atr2', 'Atr3', 'Atr4', 'Atr5', 'Atr6', 'Atr7', 'Atr8', 'Atr9', 'Atr10', 'Atr11', 'Atr12', 'Atr13', 'Atr14', 'Atr15', 'Atr16', 'Atr17', 'Atr18', 'Atr19', 'Atr20', 'Atr21', 'Atr22', 'Atr23', 'Atr24', 'Atr25', 'Atr26', 'Atr27', 'Atr28', 'Atr29', 'Atr30', 'Atr31', 'Atr32', 'Atr33', 'Atr34', 'Atr35', 'Atr36', 'Atr37', 'Atr38', 'Atr39', 'Atr40', 'Atr41', 'Atr42', 'Atr43', 'Atr44', 'Atr45', 'Atr46', 'Atr47', 'Atr48', 'Atr49', 'Atr50', 'Atr51', 'Atr52', 'Atr53', 'Atr54', 'Class']\n"
     ]
    }
   ],
   "source": [
    "dataset_name= \"divorce\"\n",
    "df = read_csv(dataset_name + \".csv\", True)\n",
    "label_column = 54\n",
    "number_of_sets = 14"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff315bfb",
   "metadata": {},
   "source": [
    "dataset_name= \"parkinsons\"\n",
    "df = read_csv(dataset_name + \"_kmeans.csv\", True)\n",
    "df = df.drop(columns = 'name')\n",
    "label_column = 17\n",
    "number_of_sets = 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd898a60",
   "metadata": {},
   "source": [
    "dataset_name= \"rice\"\n",
    "df = read_csv(dataset_name + \"_binned_kmeans.csv\", True)\n",
    "label_column = 7\n",
    "number_of_sets = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1590871e",
   "metadata": {},
   "source": [
    "dataset_name= \"wdbc\"\n",
    "df = read_csv(dataset_name + \"_binned_kmeans.csv\", True)\n",
    "df = df.drop(columns = 'ID')\n",
    "label_column = 1\n",
    "number_of_sets = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "006fe81d",
   "metadata": {},
   "source": [
    "making string columns numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f88fc608",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all string/object columns automatically\n",
    "string_columns = df.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Encode all string columns\n",
    "for column in string_columns:\n",
    "    encoder = LabelEncoder()\n",
    "    df[column] = encoder.fit_transform(df[column])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8900ca1b",
   "metadata": {},
   "source": [
    "mi for all features (graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e6a79435",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Solarize_Light2', '_classic_test_patch', '_mpl-gallery', '_mpl-gallery-nogrid', 'bmh', 'classic', 'dark_background', 'fast', 'fivethirtyeight', 'ggplot', 'grayscale', 'petroff10', 'seaborn-v0_8', 'seaborn-v0_8-bright', 'seaborn-v0_8-colorblind', 'seaborn-v0_8-dark', 'seaborn-v0_8-dark-palette', 'seaborn-v0_8-darkgrid', 'seaborn-v0_8-deep', 'seaborn-v0_8-muted', 'seaborn-v0_8-notebook', 'seaborn-v0_8-paper', 'seaborn-v0_8-pastel', 'seaborn-v0_8-poster', 'seaborn-v0_8-talk', 'seaborn-v0_8-ticks', 'seaborn-v0_8-white', 'seaborn-v0_8-whitegrid', 'tableau-colorblind10']\n"
     ]
    }
   ],
   "source": [
    "print(plt.style.available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "793e73f5",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'numpy.ndarray' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 25\u001b[39m\n\u001b[32m     20\u001b[39m     plt.show()\n\u001b[32m     23\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m x,y,mi_df\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m x,y,mi_df= \u001b[43mmi_for_all\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     26\u001b[39m mi_df.to_latex(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_mi.tex\u001b[39m\u001b[33m'\u001b[39m, index=\u001b[38;5;28;01mTrue\u001b[39;00m, float_format=\u001b[33m'\u001b[39m\u001b[38;5;132;01m%.6f\u001b[39;00m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 3\u001b[39m, in \u001b[36mmi_for_all\u001b[39m\u001b[34m(df_name, lc, title)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmi_for_all\u001b[39m(df_name = df, lc = label_column, title = \u001b[33m'\u001b[39m\u001b[33mcomplete dataset\u001b[39m\u001b[33m'\u001b[39m):\n\u001b[32m      2\u001b[39m     y = df_name.iloc[:, lc]\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     y = \u001b[43my\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m     x = df_name.drop(df_name.columns[lc], axis=\u001b[32m1\u001b[39m)\n\u001b[32m      5\u001b[39m     x = x.values\n",
      "\u001b[31mTypeError\u001b[39m: 'numpy.ndarray' object is not callable"
     ]
    }
   ],
   "source": [
    "def mi_for_all(df_name = df, lc = label_column, title = 'complete dataset'):\n",
    "    y = df_name.iloc[:, lc]\n",
    "    x = df_name.drop(df_name.columns[lc], axis=1)\n",
    "    mi_scores = mutual_info_classif(x, y, discrete_features=True)\n",
    "    mi_df = pd.DataFrame({\"Feature\": x.columns, \"MI_Score\": mi_scores}).sort_values(by=\"MI_Score\", ascending=False)\n",
    "    print(mi_df)\n",
    "\n",
    "    # Create line plot\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    ax.plot(mi_df[\"Feature\"], mi_df[\"MI_Score\"], marker='o')\n",
    "    ax.set_xlabel(\"Features\")\n",
    "    ax.set_ylabel(\"MI Values\")\n",
    "    ax.set_title(f\"Mutual Information Scores {dataset_name.title()} Dataset\")\n",
    "    plt.style.use('seaborn-v0_8')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'mi {dataset_name} {title}.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    return x,y,mi_df\n",
    "\n",
    "x,y,mi_df= mi_for_all()\n",
    "mi_df.to_latex(f'{dataset_name}_mi.tex', index=True, float_format='%.6f')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d66535",
   "metadata": {},
   "source": [
    "vertical split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f545ccf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target columns count (divide into 3 parts, take integer)\n",
    "#total_columns = df.shape[1]\n",
    "#target_columns_count = total_columns // 3\n",
    "# Pick random feature columns from total number of columns from dataset x\n",
    "#random.seed(42)\n",
    "#random_cols = random.sample(range(x.shape[1]), target_columns_count - 1)\n",
    "# Build target_set (label first, then random features)\n",
    "#target_features = x.iloc[:, random_cols]\n",
    "#target_set = pd.concat([y, target_features], axis=1)\n",
    "#remaining_set = x.drop(x.columns[random_cols], axis=1)\n",
    "#print(\"Target columns count:\", target_columns_count)\n",
    "#print(\"Selected feature indices:\", random_cols)\n",
    "#print(target_set.head(), \"\\n\")\n",
    "#print(remaining_set.head())\n",
    "\n",
    "# Split the feature indices into groups\n",
    "parts = np.array_split(np.arange(df.shape[1]), number_of_sets, axis=0)\n",
    "\n",
    "# Get the first group of feature indices\n",
    "#target_feature_indices = parts[0]\n",
    "\n",
    "# Select the target features using column indices\n",
    "#target_features = x.iloc[:, target_feature_indices]\n",
    "\n",
    "# Create target set by concatenating y with target features\n",
    "#target_set = pd.concat([y, target_features], axis=1)\n",
    "print(\"Parts:\")\n",
    "for i, part in enumerate(parts):\n",
    "    print(f\"Part {i}: {part}\")\n",
    "\n",
    "target_set = None\n",
    "\n",
    "# Find which part has the label column and get that part\n",
    "for part in parts:\n",
    "    if label_column in part:\n",
    "        target_set = df.iloc[:, part]\n",
    "        break\n",
    "\n",
    "if target_set is not None:\n",
    "    print(f\"Target set shape: {target_set.shape}\")\n",
    "else:\n",
    "    print(f\"Label column {label_column} not found in any part\")\n",
    "\n",
    "#make label first column on target_set \n",
    "label_col = df.columns[label_column]\n",
    "col_data = target_set.pop(label_col)  # Remove the column\n",
    "target_set.insert(0, label_col, col_data)  # Insert it at position 0\n",
    "\n",
    "#make label first column on target_set and the last column will be the lowst mi on target_set\n",
    "label_col = df.columns[label_column]\n",
    "col_data = target_set.pop(label_col)  # Remove the column\n",
    "target_set.insert(0, label_col, col_data)  # Insert it at position 0\n",
    "# Create remaining set by dropping the target feature columns\n",
    "#remaining_set = x.drop(x.columns[target_feature_indices], axis=1)\n",
    "\n",
    "#print(\"Selected feature indices:\", target_feature_indices)\n",
    "\n",
    "#print(\"Remaining set shape:\", remaining_set.shape)\n",
    "#print(remaining_set.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3912733",
   "metadata": {},
   "source": [
    "mi on the set with label to find the target (lowest mi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e6f36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get MI scores and find lowest MI column\n",
    "a,b,target_mi_df = mi_for_all(df_name=target_set, lc=0, title = 'in target set')\n",
    "\n",
    "lowest_mi_column = target_mi_df.iloc[-1]['Feature']\n",
    "print(f\"Column with lowest MI: {lowest_mi_column}\")\n",
    "\n",
    "# Calculate Spearman correlations\n",
    "lowest_mi_data = target_set[lowest_mi_column]\n",
    "correlations = x.corrwith(lowest_mi_data, method='spearman')\n",
    "\n",
    "# Convert to DataFrame and sort\n",
    "corr_df = pd.DataFrame({\n",
    "    'Feature': correlations.index,\n",
    "    'Spearman_Correlation': correlations.abs().values\n",
    "}).sort_values('Spearman_Correlation', ascending=False)\n",
    "\n",
    "# Remove the column that correlates with itself\n",
    "corr_df = corr_df[corr_df['Feature'] != lowest_mi_column]\n",
    "\n",
    "print(f\"Spearman correlations between '{lowest_mi_column}' and x:\")\n",
    "print(corr_df)\n",
    "\n",
    "# Create line plot\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "ax.plot(corr_df[\"Feature\"], corr_df[\"Spearman_Correlation\"], marker='o')\n",
    "ax.set_xlabel(\"Features\")\n",
    "ax.set_ylabel(\"Abs. Corrolation Values\")\n",
    "ax.set_title(f\"Target= {lowest_mi_column} Feature Corrolations {dataset_name.title()} Dataset\")\n",
    "plt.style.use('seaborn-v0_8')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{dataset_name} spearman correlation.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "corr_df.to_latex(f'{dataset_name}_corr.tex', index=True, float_format='%.6f')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e583210",
   "metadata": {},
   "source": [
    "spearman with target to varibales that are outside the set (graph to see elbow)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
