{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "1db7e050",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_selection import mutual_info_classif   \n",
    "import gmpy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "b30557bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASETS = {\n",
    "    'diabetes': ('diabetes_kmeans.csv', 'Outcome', [])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "b4e7b25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_int(x):\n",
    "    return int(x) if not isinstance(x, int) else x\n",
    "\n",
    "def log2_safe(p: gmpy2.mpfr):\n",
    "    return gmpy2.log2(p) if p > 0 else gmpy2.mpfr(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "14c9860d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_csv_data(filename, target_col, drop_cols=None):\n",
    "    df = pd.read_csv(filename, delimiter=',')\n",
    "    if drop_cols:\n",
    "        df = df.drop(columns=drop_cols, errors='ignore')\n",
    "    df = df.apply(lambda s: s.astype(np.int64) if s.name != target_col else s)\n",
    "    data_parts = np.array_split(df, 3, axis=1)\n",
    "    original_data = pd.concat(data_parts, axis=1)\n",
    "    return data_parts, original_data\n",
    "\n",
    "def load_dataset(name):\n",
    "    if name not in DATASETS:\n",
    "        raise ValueError(f\"Unknown dataset: {name}\")\n",
    "    file, target, drops = DATASETS[name]\n",
    "    data_parts, original_data = load_csv_data(file, target, drops)\n",
    "    return (data_parts, original_data), target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "1fa45f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compute_mutual_information(data_parts, target_col):\n",
    "    # Locate target column\n",
    "    target_series = None\n",
    "    for p in data_parts:\n",
    "        if target_col in p.columns:\n",
    "            target_series = p[target_col]\n",
    "            break\n",
    "    if target_series is None:\n",
    "        return {}\n",
    "    n = len(target_series)\n",
    "    unique_Y = pd.unique(target_series)\n",
    "    # Precompute Y indicators & entropy H(Y)\n",
    "    Y_ind = {y: (target_series == y).astype(int).to_numpy() for y in unique_Y}\n",
    "    H_y = gmpy2.mpfr(0)\n",
    "    for y in unique_Y:\n",
    "        py = gmpy2.mpfr(int(Y_ind[y].sum())) / gmpy2.mpfr(n)\n",
    "        if py > 0:\n",
    "            H_y -= py * log2_safe(py)\n",
    "    mi = {}\n",
    "    for part in data_parts:\n",
    "        for col in part.columns:\n",
    "            if col == target_col:\n",
    "                continue\n",
    "            X = part[col]\n",
    "            unique_X = pd.unique(X)\n",
    "            X_ind = {xv: (X == xv).astype(int).to_numpy() for xv in unique_X}\n",
    "            count_x = {xv: X_ind[xv].sum() for xv in unique_X}\n",
    "            H_y_given_x = gmpy2.mpfr(0)\n",
    "            for xv in unique_X:\n",
    "                cx = count_x[xv]\n",
    "                if cx == 0:\n",
    "                    continue\n",
    "                for y in unique_Y:\n",
    "                    c_xy = int((X_ind[xv] & Y_ind[y]).sum())\n",
    "                    if c_xy == 0:\n",
    "                        continue\n",
    "                    p_xy = gmpy2.mpfr(c_xy) / gmpy2.mpfr(n)\n",
    "                    p_y_given_x = gmpy2.mpfr(c_xy) / cx\n",
    "                    H_y_given_x -= p_xy * log2_safe(p_y_given_x)\n",
    "            mi[col] = float(H_y - H_y_given_x)\n",
    "    return mi\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "e14471f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_min_mutual_info_feature(data_parts, target_col):\n",
    "    plain_mi_score = compute_mutual_information(data_parts, target_col)\n",
    "    print(\"Plain MI Scores:\", plain_mi_score)\n",
    "    for part in data_parts:\n",
    "        if target_col in part.columns:\n",
    "            feature_cols = [c for c in part.columns if c != target_col]\n",
    "            if not feature_cols:\n",
    "                raise ValueError(\"No feature columns in target-containing part.\")\n",
    "            min_feature = min(feature_cols, key=lambda c: plain_mi_score.get(c, float('inf')))\n",
    "            return min_feature\n",
    "    raise ValueError(f\"Target column '{target_col}' not found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb837313",
   "metadata": {},
   "source": [
    "\n",
    "def compute_ranks(data_parts, target_col):\n",
    "    ranks = []\n",
    "    original_data = pd.concat(data_parts, axis=1)\n",
    "    \n",
    "    for part in data_parts:\n",
    "        cols = [c for c in part.columns if c != target_col]\n",
    "        if cols:\n",
    "            # Use original_data for ranking, but select only columns from current part\n",
    "            ranks.append(original_data[cols].rank().astype(int))\n",
    "        else:\n",
    "            ranks.append(pd.DataFrame(index=part.index))\n",
    "    return ranks\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b96efed4",
   "metadata": {},
   "source": [
    "def compute_spearman_correlation(ranked_parts, target_col, data_parts):\n",
    "    # Find which part (if any) has target ranks; fallback: last part\n",
    "    target_rank = None\n",
    "    for rp in ranked_parts:\n",
    "        if target_col in rp.columns:\n",
    "            target_rank = rp[target_col].astype(int)\n",
    "            break\n",
    "    # If target ranks are not stored separately, cannot proceed\n",
    "    if target_rank is None:\n",
    "        # Assume target in last original part (not ranked); cannot compute -> return empty\n",
    "        return {}\n",
    "    n = len(target_rank)\n",
    "    denom = n * (n**2 - 1)\n",
    "    res = {}\n",
    "    for rp in ranked_parts:\n",
    "        for col in rp.columns:\n",
    "            if col == target_col:\n",
    "                continue\n",
    "            fr = rp[col].astype(int)\n",
    "            d2 = (fr - target_rank).apply(lambda d: d * d).sum()\n",
    "            res[col] = 1 - (6 * d2) / denom\n",
    "    \n",
    "\n",
    "    print(f\"Your calculated ranks for {target_col} (first 10):\")\n",
    "    print(target_rank.head(10).tolist())\n",
    "    \n",
    "    for rp in ranked_parts:\n",
    "        for col in rp.columns:\n",
    "            if col == target_col:\n",
    "                continue\n",
    "                \n",
    "            fr = rp[col].astype(int)\n",
    "            \n",
    "            # DEBUG: Print sample ranks for this feature\n",
    "            print(f\"\\nYour calculated ranks for {col} (first 10):\")\n",
    "            print(fr.head(10).tolist())\n",
    "            \n",
    "            # DEBUG: Compare with pandas direct calculation\n",
    "            # Get original data and calculate ranks directly\n",
    "            original_data = pd.concat(data_parts, axis=1)\n",
    "            pandas_rank_target = original_data[target_col].rank(method='average').astype(int)\n",
    "            pandas_rank_feature = original_data[col].rank(method='average').astype(int)\n",
    "            \n",
    "            print(f\"Pandas ranks for {target_col} (first 10):\")\n",
    "            print(pandas_rank_target.head(10).tolist())\n",
    "            print(f\"Pandas ranks for {col} (first 10):\")\n",
    "            print(pandas_rank_feature.head(10).tolist())\n",
    "            \n",
    "            break  # Just check first feature for now\n",
    "        break\n",
    "    print(f\"res:{res}\")\n",
    "    return res\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "2451443f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compute_ranks(original_data, target_col):\n",
    "    \"\"\"\n",
    "    Compute ranks for all columns except the target column.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    original_data : pd.DataFrame\n",
    "        The complete dataset\n",
    "    target_col : str\n",
    "        Name of the target column\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame\n",
    "        DataFrame with ranked values for all feature columns\n",
    "    \"\"\"\n",
    "    cols = [c for c in original_data.columns if c != target_col]\n",
    "    if cols:\n",
    "        ranked_data = original_data[cols].rank().astype(int)\n",
    "    else:\n",
    "        ranked_data = pd.DataFrame(index=original_data.index)\n",
    "    return ranked_data\n",
    "\n",
    "def compute_spearman_correlation(original_data, min_feature, target_col):\n",
    "    \"\"\"\n",
    "    Compute Spearman correlation between min_feature and all other features.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    original_data : pd.DataFrame\n",
    "        The complete dataset\n",
    "    min_feature : str\n",
    "        The feature to correlate with all others\n",
    "    target_col : str\n",
    "        Name of the target column (to exclude)\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Dictionary mapping feature names to their Spearman correlation with min_feature\n",
    "    \"\"\"\n",
    "    if min_feature not in original_data.columns:\n",
    "        return {}\n",
    "    \n",
    "    # Get min_feature ranks\n",
    "    min_feature_rank = original_data[min_feature].rank().astype(int)\n",
    "    n = len(min_feature_rank)\n",
    "    denom = n * (n**2 - 1)\n",
    "    \n",
    "    res = {}\n",
    "    for col in original_data.columns:\n",
    "        # Skip the min_feature itself and the target column\n",
    "        if col == min_feature or col == target_col:\n",
    "            continue\n",
    "        \n",
    "        feature_rank = original_data[col].rank().astype(int)\n",
    "        d2 = ((feature_rank - min_feature_rank) ** 2).sum()\n",
    "        res[col] = 1 - (6 * d2) / denom\n",
    "    \n",
    "    print(f\"res:{res}\")\n",
    "\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "15681de5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plain MI Scores: {'Pregnancies': 0.04791176873782721, 'Glucose': 0.188578888220306, 'BloodPressure': 0.027567905180460817, 'SkinThickness': 0.04315827716728404, 'Insulin': 0.05990375098362566, 'BMI': 0.09043066514352194, 'DiabetesPedigreeFunction': 0.03320503661584395, 'Age': 0.08231736993762473}\n",
      "res:{'Pregnancies': np.float64(0.028008124365275666), 'Glucose': np.float64(0.15358134982867744), 'BloodPressure': np.float64(0.08952660639293486), 'SkinThickness': np.float64(0.23816241800506255), 'Insulin': np.float64(0.3088322285880679), 'BMI': np.float64(0.19381295055889647), 'Age': np.float64(0.11354750439962502)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Can/VsCodeProjects/bitirme projesi/.venv/lib/python3.12/site-packages/numpy/_core/fromnumeric.py:57: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
      "  return bound(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def main(dataset_name='diabetes'):\n",
    "    (parts_list, original_data), target_col = load_dataset(dataset_name)\n",
    "    \n",
    "    # Use parts_list for functions that need data_parts\n",
    "    min_feature = get_min_mutual_info_feature(parts_list, target_col)\n",
    "    \n",
    "    # Use original_data for the new functions\n",
    "    ranked_data = compute_ranks(original_data, target_col)\n",
    "    \n",
    "    # Compute correlation between min_feature and all other features\n",
    "    plain_spearman = compute_spearman_correlation(original_data, min_feature, target_col)\n",
    "    \n",
    "    return plain_spearman\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main('diabetes')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
