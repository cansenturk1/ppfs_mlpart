{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1db7e050",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "import gmpy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b30557bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASETS = {\n",
    "    'beans': ('beans_kmeans.csv', 'Class', []),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38f783b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_int(x):\n",
    "    return int(x) if not isinstance(x, int) else x\n",
    "\n",
    "def log2_safe(p: gmpy2.mpfr):\n",
    "    return gmpy2.log2(p) if p > 0 else gmpy2.mpfr(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14c9860d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_csv_data(filename, target_col, drop_cols=None):\n",
    "    df = pd.read_csv(filename, delimiter=',')\n",
    "    if drop_cols:\n",
    "        df = df.drop(columns=drop_cols, errors='ignore')\n",
    "    df = df.apply(lambda s: s.astype(np.int64) if s.name != target_col else s)\n",
    "    return np.array_split(df, 3, axis=1)\n",
    "\n",
    "def load_dataset(name):\n",
    "    if name not in DATASETS:\n",
    "        raise ValueError(f\"Unknown dataset: {name}\")\n",
    "    file, target, drops = DATASETS[name]\n",
    "    return load_csv_data(file, target, drops), target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e14471f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_min_mutual_info_feature(data_parts, target_col):\n",
    "    for part in data_parts:\n",
    "        if target_col in part.columns:\n",
    "            feature_cols = [c for c in part.columns if c != target_col]\n",
    "            if not feature_cols:\n",
    "                raise ValueError(\"No feature columns in target-containing part.\")\n",
    "            X = part[feature_cols].values\n",
    "            y = part[target_col].values\n",
    "            mi_scores = mutual_info_classif(X, y, discrete_features=True)\n",
    "            return min(dict(zip(feature_cols, mi_scores)), key=lambda k: mi_scores[feature_cols.index(k)])\n",
    "    raise ValueError(f\"Target column '{target_col}' not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb837313",
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_int(x):\n",
    "    return int(x) if not isinstance(x, int) else x\n",
    "\n",
    "def log2_safe(p: gmpy2.mpfr):\n",
    "    return gmpy2.log2(p) if p > 0 else gmpy2.mpfr(0)\n",
    "\n",
    "# =====================================================================\n",
    "# Mutual Information (Plain)\n",
    "# =====================================================================\n",
    "\n",
    "def compute_mutual_information(data_parts, target_col):\n",
    "    # Locate target column\n",
    "    target_series = None\n",
    "    for p in data_parts:\n",
    "        if target_col in p.columns:\n",
    "            target_series = p[target_col]\n",
    "            break\n",
    "    if target_series is None:\n",
    "        return {}\n",
    "    n = len(target_series)\n",
    "    unique_Y = pd.unique(target_series)\n",
    "    # Precompute Y indicators & entropy H(Y)\n",
    "    Y_ind = {y: (target_series == y).astype(int).to_numpy() for y in unique_Y}\n",
    "    H_y = gmpy2.mpfr(0)\n",
    "    for y in unique_Y:\n",
    "        py = gmpy2.mpfr(int(Y_ind[y].sum())) / gmpy2.mpfr(n)\n",
    "        if py > 0:\n",
    "            H_y -= py * log2_safe(py)\n",
    "    mi = {}\n",
    "    for part in data_parts:\n",
    "        for col in part.columns:\n",
    "            if col == target_col:\n",
    "                continue\n",
    "            X = part[col]\n",
    "            unique_X = pd.unique(X)\n",
    "            X_ind = {xv: (X == xv).astype(int).to_numpy() for xv in unique_X}\n",
    "            count_x = {xv: X_ind[xv].sum() for xv in unique_X}\n",
    "            H_y_given_x = gmpy2.mpfr(0)\n",
    "            for xv in unique_X:\n",
    "                cx = count_x[xv]\n",
    "                if cx == 0:\n",
    "                    continue\n",
    "                for y in unique_Y:\n",
    "                    c_xy = int((X_ind[xv] & Y_ind[y]).sum())\n",
    "                    if c_xy == 0:\n",
    "                        continue\n",
    "                    p_xy = gmpy2.mpfr(c_xy) / gmpy2.mpfr(n)\n",
    "                    p_y_given_x = gmpy2.mpfr(c_xy) / cx\n",
    "                    H_y_given_x -= p_xy * log2_safe(p_y_given_x)\n",
    "            mi[col] = float(H_y - H_y_given_x)\n",
    "    return mi"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
