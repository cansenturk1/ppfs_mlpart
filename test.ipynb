{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1db7e050",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_selection import mutual_info_classif   \n",
    "import gmpy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b30557bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASETS = {\n",
    "    'diabetes': ('diabetes_kmeans.csv', 'Outcome', [])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b4e7b25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_int(x):\n",
    "    return int(x) if not isinstance(x, int) else x\n",
    "\n",
    "def log2_safe(p: gmpy2.mpfr):\n",
    "    return gmpy2.log2(p) if p > 0 else gmpy2.mpfr(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "14c9860d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_csv_data(filename, label_col, drop_cols=None):\n",
    "    df = pd.read_csv(filename, delimiter=',')\n",
    "    if drop_cols:\n",
    "        df = df.drop(columns=drop_cols, errors='ignore')\n",
    "    df = df.apply(lambda s: s.astype(np.int64) if s.name != label_col else s)\n",
    "    data_parts = np.array_split(df, 3, axis=1)\n",
    "    return np.array_split(df, 3, axis=1), df\n",
    "\n",
    "def load_dataset(name):\n",
    "    if name not in DATASETS:\n",
    "        raise ValueError(f\"Unknown dataset: {name}\")\n",
    "    file, target, drops = DATASETS[name]\n",
    "    data_parts, df = load_csv_data(file, target, drops)\n",
    "    return data_parts, df, target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1fa45f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compute_mutual_information(data_parts, label_col):\n",
    "    # Locate target column\n",
    "    target_series = None\n",
    "    for p in data_parts:\n",
    "        if label_col in p.columns:\n",
    "            target_series = p[label_col]\n",
    "            break\n",
    "    if target_series is None:\n",
    "        return {}\n",
    "    n = len(target_series)\n",
    "    unique_Y = pd.unique(target_series)\n",
    "    # Precompute Y indicators & entropy H(Y)\n",
    "    Y_ind = {y: (target_series == y).astype(int).to_numpy() for y in unique_Y}\n",
    "    H_y = gmpy2.mpfr(0)\n",
    "    for y in unique_Y:\n",
    "        py = gmpy2.mpfr(int(Y_ind[y].sum())) / gmpy2.mpfr(n)\n",
    "        if py > 0:\n",
    "            H_y -= py * log2_safe(py)\n",
    "    mi = {}\n",
    "    for part in data_parts:\n",
    "        for col in part.columns:\n",
    "            if col == label_col:\n",
    "                continue\n",
    "            X = part[col]\n",
    "            unique_X = pd.unique(X)\n",
    "            X_ind = {xv: (X == xv).astype(int).to_numpy() for xv in unique_X}\n",
    "            count_x = {xv: X_ind[xv].sum() for xv in unique_X}\n",
    "            H_y_given_x = gmpy2.mpfr(0)\n",
    "            for xv in unique_X:\n",
    "                cx = count_x[xv]\n",
    "                if cx == 0:\n",
    "                    continue\n",
    "                for y in unique_Y:\n",
    "                    c_xy = int((X_ind[xv] & Y_ind[y]).sum())\n",
    "                    if c_xy == 0:\n",
    "                        continue\n",
    "                    p_xy = gmpy2.mpfr(c_xy) / gmpy2.mpfr(n)\n",
    "                    p_y_given_x = gmpy2.mpfr(c_xy) / cx\n",
    "                    H_y_given_x -= p_xy * log2_safe(p_y_given_x)\n",
    "            mi[col] = float(H_y - H_y_given_x)\n",
    "    return mi\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e14471f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_min_mutual_info_feature(data_parts, label_col):\n",
    "    plain_mi_score = compute_mutual_information(data_parts, label_col)\n",
    "    print(\"Plain MI Scores:\", plain_mi_score)\n",
    "    for part in data_parts:\n",
    "        if label_col in part.columns:\n",
    "            feature_cols = [c for c in part.columns if c != label_col]\n",
    "            if not feature_cols:\n",
    "                raise ValueError(\"No feature columns in target-containing part.\")\n",
    "            min_feature = min(feature_cols, key=lambda c: plain_mi_score.get(c, float('inf')))\n",
    "            return min_feature\n",
    "    raise ValueError(f\"Target column '{label_col}' not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "3d9b211d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ranks(data_parts, label_col):\n",
    "    ranks = []\n",
    "    for part in data_parts:\n",
    "        cols = [c for c in part.columns if c != label_col]\n",
    "        if cols:\n",
    "            # Use method='average' to handle ties, will be converted to int later\n",
    "            ranks.append(part[cols].rank(method='average').astype(int))\n",
    "        else:\n",
    "            ranks.append(pd.DataFrame(index=part.index))\n",
    "    return ranks\n",
    "\n",
    "\n",
    "def compute_spearman_correlation(ranked_parts, correlation_target):\n",
    "    # Find which part (if any) has target ranks; fallback: last part\n",
    "    target_rank = None\n",
    "    for rp in ranked_parts:\n",
    "        if correlation_target in rp.columns:\n",
    "            target_rank = rp[correlation_target].astype(int)\n",
    "            break\n",
    "    # If target ranks are not stored separately, cannot proceed\n",
    "    if target_rank is None:\n",
    "        # Assume target in last original part (not ranked); cannot compute -> return empty\n",
    "        return {}\n",
    "    \n",
    "    res = {}\n",
    "    for rp in ranked_parts:\n",
    "        for col in rp.columns:\n",
    "            if col == correlation_target:\n",
    "                continue\n",
    "            \n",
    "            feature_rank = rp[col].astype(int)\n",
    "            \n",
    "            # ρ = cov(R_x, R_y) / (std(R_x) * std(R_y))\n",
    "            mean_feature = feature_rank.mean()\n",
    "            mean_target = target_rank.mean()\n",
    "            \n",
    "            # Covariance\n",
    "            cov = ((feature_rank - mean_feature) * (target_rank - mean_target)).sum()\n",
    "            \n",
    "            # Standard deviations\n",
    "            std_feature = ((feature_rank - mean_feature) ** 2).sum() ** 0.5\n",
    "            std_target = ((target_rank - mean_target) ** 2).sum() ** 0.5\n",
    "            \n",
    "            # Pearson correlation on ranks (Spearman correlation)\n",
    "            if std_feature > 0 and std_target > 0:\n",
    "                res[col] = cov / (std_feature * std_target)\n",
    "            else:\n",
    "                res[col] = 0.0  # Handle case where all ranks are identical\n",
    "\n",
    "    print(f\"res:{res}\")\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "408d3293",
   "metadata": {},
   "source": [
    "def compute_ranks(df, label_col):\n",
    "    \"\"\"\n",
    "    Compute ranks for all columns in df except label_col\n",
    "    \n",
    "    Parameters:\n",
    "    - df: pd.DataFrame - the full dataset\n",
    "    - label_col: str - the label column to exclude from ranking\n",
    "    \n",
    "    Returns:\n",
    "    - pd.DataFrame with ranked values\n",
    "    \"\"\"\n",
    "    cols = [c for c in df.columns if c != label_col]\n",
    "    if cols:\n",
    "        ranks = df[cols].rank().astype(int)\n",
    "    else:\n",
    "        ranks = pd.DataFrame(index=df.index)\n",
    "    \n",
    "    return ranks\n",
    "\n",
    "\n",
    "def compute_spearman_correlation(df, correlation_target, label_col):\n",
    "    \"\"\"\n",
    "    Compute Spearman correlation between features and correlation target\n",
    "    \n",
    "    Parameters:\n",
    "    - df: pd.DataFrame - the full dataset\n",
    "    - correlation_target: str - the target column for correlation\n",
    "    - label_col: str - the label column to exclude\n",
    "    \n",
    "    Returns:\n",
    "    - dict mapping feature names to their Spearman correlation with target\n",
    "    \"\"\"\n",
    "\n",
    "    cols = [c for c in df.columns if c != label_col]\n",
    "    \n",
    "    if correlation_target not in cols:\n",
    "        print(f\"Warning: {correlation_target} not found in data\")\n",
    "        return {}\n",
    "    \n",
    "    # Rank each column independently\n",
    "    ranked_data = df[cols].rank(method='average').astype(int)\n",
    "    \n",
    "    target_rank = ranked_data[correlation_target].astype(int)\n",
    "    \n",
    "    res = {}\n",
    "    for col in ranked_data.columns:\n",
    "        if col == correlation_target:\n",
    "            continue\n",
    "        \n",
    "        fr = ranked_data[col].astype(int)\n",
    "        \n",
    "        # Use Pearson correlation on ranks\n",
    "        mean_fr = fr.mean()\n",
    "        mean_target = target_rank.mean()\n",
    "        \n",
    "        numerator = ((fr - mean_fr) * (target_rank - mean_target)).sum()\n",
    "        denominator = (((fr - mean_fr) ** 2).sum() ** 0.5) * (((target_rank - mean_target) ** 2).sum() ** 0.5)\n",
    "        \n",
    "        res[col] = numerator / denominator if denominator != 0 else 0\n",
    "    \n",
    "    print(f\"res:{res}\")\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "907ac42c",
   "metadata": {},
   "source": [
    "\n",
    "def main(dataset_name='diabetes'):\n",
    "    data_parts, df, label_col = load_dataset(dataset_name)\n",
    "\n",
    "    correlation_target = get_min_mutual_info_feature(data_parts, label_col)\n",
    "    ranked_parts = compute_ranks(df,label_col)\n",
    "\n",
    "    # Spearman\n",
    "    plain_spearman = compute_spearman_correlation(df, correlation_target, label_col)\n",
    "\n",
    "    # Mutual Information\n",
    "    plain_mi = compute_mutual_information(data_parts, label_col)\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main('diabetes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "15681de5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plain MI Scores: {'Pregnancies': 0.04791176873782721, 'Glucose': 0.188578888220306, 'BloodPressure': 0.027567905180460817, 'SkinThickness': 0.04315827716728404, 'Insulin': 0.05990375098362566, 'BMI': 0.09043066514352194, 'DiabetesPedigreeFunction': 0.03320503661584395, 'Age': 0.08231736993762473}\n",
      "res:{'Pregnancies': np.float64(-0.04603966358699283), 'Glucose': np.float64(0.10309609084897267), 'BloodPressure': np.float64(0.019086198116041148), 'SkinThickness': np.float64(0.18465164310327667), 'Insulin': np.float64(0.21469476082425581), 'BMI': np.float64(0.1404365687528146), 'Age': np.float64(0.03545689313425083)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\VS Code Projects\\ppfs_mlpart\\.venv\\Lib\\site-packages\\numpy\\_core\\fromnumeric.py:57: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
      "  return bound(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "def main(dataset_name='diabetes'):\n",
    "    data_parts, df, label_col = load_dataset(dataset_name)\n",
    "\n",
    "    correlation_target = get_min_mutual_info_feature(data_parts, label_col)\n",
    "    ranked_parts = compute_ranks(data_parts, label_col)\n",
    "\n",
    "    # Spearman\n",
    "    plain_spearman = compute_spearman_correlation(ranked_parts, correlation_target)\n",
    "\n",
    "    # Mutual Information\n",
    "    plain_mi = compute_mutual_information(data_parts, label_col)\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main('diabetes')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.10)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
